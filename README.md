# Awesome-LLM-Fine-Tuning
LLM fine-tuning 


# Papers 


## Unsupervised Fine-Tuning 

### Unsupervised Full Fine-Tuning

### Contrastive Learning 


## Supervised Fine-Tuning Methods

### Parameter-Efficient Fine-Tuning (PEFT)


### Supervised Full Fine-Tuning 


### Instruction Fine-Tuning 

**Finetuned Language Models are Zero-Shot Learners**
*Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, Quoc V Le*
ICLR 2022. [[Paper](https://openreview.net/forum?id=gEZrGCozdqR)]



### Reinforcement Learning from Human Feedback (RLHF)



### Direct Policy Optimization (DPO)

**Direct Preference Optimization: Your Language Model is Secretly a Reward Model** 
*Rafael Rafailov, Archit Sharma, Eric Mitchell, Stefano Ermon, Christopher D. Manning, Chelsea Finn* 
NeurIPS 2023. [[Paper](https://openreview.net/forum?id=HPuSIXJaa9&utm_source=substack&utm_medium=email)]


## RAG vs Fine-tuning 

**Fine-Tuning or Retrieval? Comparing Knowledge Injection in LLMs**
*Oded Ovadia, Menachem Brief, Moshik Mishaeli, Oren Elisha*
arXiv, 2023. [[Paper](https://arxiv.org/abs/2312.05934)]

**Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge** 
*Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi*
arXiv, 2024. [[Paper](https://arxiv.org/abs/2403.01432)][[Github](https://github.com/heydarsoudani/ragvsft)]


## Knowledge, Data 



<!-- course
https://github.com/aishwaryanr/awesome-generative-ai-guide/blob/main/free_courses/Applied_LLMs_Mastery_2024/week3_finetuning_llms.md
 -->